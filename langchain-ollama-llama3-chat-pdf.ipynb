{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Llama3-8B LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "(Wait for it...)\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "Hope that made you smile! Do you want to hear another one?\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"llama3:8b\"\n",
    "\n",
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "\n",
    "print(model.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the chain and set the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code useful for converting into a clean string format, but llama3 already does this\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser \n",
    "# print(chain.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Fahri.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"context\": \"My name is Fahri\", \"question\": \"What's your name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PDF files and split that into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:17<00:00,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 documents loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\"sample-pdf\", glob=\"*.pdf\", show_progress=True)\n",
    "documents = loader.load()\n",
    "print(len(documents), \"documents loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector database and store the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lebnovo\\local-model\\.venv\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(texts, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create retriever and chain it with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the main focus of the course HL 2090 Special Topic in Literature, I: Literature and Economics?\n",
      "Answer: The main focus of the course HL 2090 Special Topic in Literature, I: Literature and Economics is an introduction to economic concepts and ideas through their dramatization in literature.\n",
      "\n",
      "Question: What's the website that provide NTU Academic Integrity Guidelines?\n",
      "Answer: http://www.ntu.edu.sg/ai/Pages/academic-integrity-policy.aspx\n",
      "\n",
      "Question: What if you wish to use the materials for your assignments?\n",
      "Answer: You must cite them accordingly.\n",
      "\n",
      "Question: Can you list the books mentioned in the course?\n",
      "Answer: Based on the context, here are the books mentioned in the course:\n",
      "\n",
      "1. Fitzgerald's The Great Gatsby\n",
      "2. Hamid's How to Get Filthy Rich in Rising Asia\n",
      "3. Kwan's Crazy Rich Asians\n",
      "4. Norris's McTeague (specifically mentioning Signet, Penguin, Dover, or Norton edition)\n",
      "\n",
      "Let me know if you have any further questions!\n",
      "\n",
      "Question: Can you provide the English Language requirement?\n",
      "Answer: According to the context, it seems that there is no specific information provided about the English Language requirement. However, I can tell you that for certain qualifications, additional English Language test scores are required in addition to high school qualifications. If you're looking for more detailed information, please let me know which qualification or examination you're referring to, and I'll do my best to help!\n",
      "\n",
      "Question: What is the minimum acceptable score for the TOEFL iBT test?\n",
      "Answer: I don't know. The provided context does not mention any specific information about the minimum acceptable score for the TOEFL iBT test. It only lists various English language tests, including TOEFL iBT, but does not provide a specific threshold or requirement for the test scores.\n",
      "\n",
      "Question: How long is the validity of the MUET score?\n",
      "Answer: According to the context, the answer is: five years.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is the main focus of the course HL 2090 Special Topic in Literature, I: Literature and Economics?\",\n",
    "    \"What's the website that provide NTU Academic Integrity Guidelines?\",\n",
    "    \"What if you wish to use the materials for your assignments?\",\n",
    "    \"Can you list the books mentioned in the course?\",\n",
    "    \"Can you provide the English Language requirement?\",\n",
    "    \"What is the minimum acceptable score for the TOEFL iBT test?\",\n",
    "    \"How long is the validity of the MUET score?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The provided context does not contain any information about the NUS institution code for TOEFL. It appears to be a collection of documents related to an academic course, including pages from PDF files that mention English proficiency and plagiarism guidelines, but do not provide specific information on TOEFL codes."
     ]
    }
   ],
   "source": [
    "for s in chain.stream({\"question\": \"What's the NUS institution code for TOEFL?\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
